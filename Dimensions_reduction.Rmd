---
title: 'World happiness study: dimensions reduction'
output:
  html_document: 
    toc: yes
    df_print: paged
    toc_depth: 3
---

<br/>

```{r document_details, echo = FALSE}
cat(" Author: Kiril Boyanov (kirilboyanov [at] gmail.com)\n", "LinkedIn: www.linkedin.com/kirilboyanov/\n", "Last update:", format(Sys.Date(), "%Y-%m-%d"))
```

<br/>

In this file, we import the already clean data (where we've also made imputations for missing values). After that, we try to construct a simplified set of variables that reflects the overall categories, i.e. economic, political, social, environmental and health-related factors. We use principal component analysis (PCA) as our preferred dimension reduction technique.

<br/>

# Setting things up

Importing relevant packages, defining custom functions, specifying local folders etc.

```{r input_folder, echo = FALSE}
# User input: specifying the local path to the folder
# where the analysis data are to be stored
AnalysisFolder <- "G:/My Drive/Projects/Data & statistics/Happiness insights/"
```

```{r library_import, message = FALSE, warning = FALSE}
# Importing relevant packages

# For general data-related tasks
library(plyr)
library(tidyverse)
library(data.table)
library(openxlsx)
library(readxl)
library(arrow)
library(zoo)

# For working with countries
library(countrycode)

# For statistical analysis
library(stats)
library(factoextra)

# For data visualization
library(ggplot2)
library(plotly)
library(rjson)
```

```{r custom_functions, echo=FALSE}
# Importing custom functions created for this project
source("Custom_functions.R")
```

<br/>

# User input

Throughout the analysis, we will be using a common `BaseYear` (to represent the past state of happiness) and a common `ReferenceYear` (to represent the most recent state of happiness). To ensure consistency across files, these two years are stored in a TXT file, which is imported below.

Thus, we use the following years as base and reference:

```{r defining_years, warning = FALSE,  echo = FALSE}
# Importing the parameters
YearsToUse <- readLines(paste(AnalysisFolder, "Years to use.txt", sep = ""))
YearsToUse <- unlist(str_split(YearsToUse, ","))
BaseYear <- as.numeric(YearsToUse[1])
ReferenceYear <- as.numeric(YearsToUse[2])
rm(YearsToUse)

# Printing a confirmation
cat("Base year: ", BaseYear, "\n")
cat("Reference year: ", ReferenceYear)
```

<br/>

# Importing data

We import data that was already pre-processed in the `WHR_data_prep.Rmd` notebook and that was subjected to missing data imputation in the `Dealing_with_missing_data.Rmd` notebook. A preview of the data imported is shown below:

```{r importing_data, echo = FALSE}
# Importing the data that's ready for use
DataForAnalysis <- read_parquet(paste(AnalysisFolder, "Data/Clean/DataForAnalysisImputed.parquet", sep = ""))

# Removing GDP in current prices
DataForAnalysis <- DataForAnalysis %>%
  select(-E_GDPPerCapitaCurrent)

# Previewing the data
head(DataForAnalysis, 5)
```

<br/>

Please note that as we have two different measures of GDP included in the data, we're dropping the one that is based on current prices so as not to overestimate the importance of GDP.

<br/>

# Method used for constructing combined factors

To facilitate the analytic work below, we combine all factors pertaining to a specific category (e.g. economics, politics etc.) into **as few variables as possible** so that we can explore the extent to which happiness is related to the more general categories as opposed to individual factors (of which we have many). In some cases, we might be able to reduce an entire category to a single dimension but in other cases, we might be left with several dimensions (though fewer than the original number).

It's important to note that in the case of having **missing values** in some rows (even after our data imputation), those rows will be **excluded** from the PCA.

Besides reducing the number of dimensions, PCA will help us because it creates components that are correlated to their factors but which are not correlated with other components.

<br/>

# Economic dimensions

Using **principal component analysis** (PCA), we're able to generate a series of dimensions that build upon all economics-related variables in our dataset (*N*=30). The chart below shows how much of the variance captured in the data is represented in each of the dimensions generated by the PCA:

```{r pca_economics_fit, echo = FALSE}
# Keeping data related to economics only
EconomicData <- DataForAnalysis %>%
  select(RowID, starts_with("E_")) %>%
  drop_na()

# Creating a temp df without RowID and standardizing
# all variables around their mean
EconomicData_ForPA <- EconomicData %>%
  select(-RowID) %>%
  mutate(across(everything(), ~ scale(.)))

# Temporarily replacing weirdly spelled column names
# and automatically specifying model to use for the CFA
EconomicData_ForPA <- create_temp_names(EconomicData_ForPA)
ColsToUse <- names(EconomicData_ForPA)

# Fitting the model
PCA_EconomicData <- princomp(x = EconomicData_ForPA)

# Visualizing the model's output
fviz_eig(PCA_EconomicData, addlabels = TRUE)
```

<br/>

Examining the output, we see a clear break-off point after the fifth factor, from where on the share of variance explained by the additional dimension is marginally low. In fact, if we stick to the **first 5 dimensions**, we will already be accounting for **80% of the variance** in the data. Keeping those dimension only, our economics data would look like this:

```{r pca_economics_dimensions, echo = FALSE}
# Defining how many dimensions to keep in the PCA output
DimensionToKeep <- 5

# Storing the results of the PCA and re-adding RowID
OutputData <- as.data.frame(PCA_EconomicData$scores) %>%
  setNames(paste0("Economics_", names(.)))
ListOfIDs <- EconomicData$RowID
OutputData <- OutputData[, 1:DimensionToKeep] %>%
  mutate(RowID = ListOfIDs) %>%
  select(RowID, everything())

# Previewing the data
head(OutputData, 5)
```

<br/>

In this way, we have reduced the total number of dimensions by 83% while only losing 20% of the variation in the data. In order to get a better understanding of which individual factors comprise the auto-generated dimensions from the PCA, we take a brief look at the 5 highest **absolute** **factor loadings**:

```{r pca_economics_correlates, echo = FALSE}
# Defining how many of the correlates to keep for getting a better understanding of what the components represent
CorrToKeep <- 5

# Extracting the factor loadings
OutputLoadings <- data.frame(PCA_EconomicData$loadings[, 1:DimensionToKeep])

# Adding the actual column names
OutputLoadings <- OutputLoadings %>%
  mutate(Factor = OriginalColNames) %>%
  select(Factor, everything())

# Ensuring the factors have the same names
ColNames <- names(OutputData)[2:length(names(OutputData))]
names(OutputLoadings) <- c("Factor", ColNames)

# Identifying the top N strongest correlates for each component
OutputLoadingsSummary <- data.frame()
for (col in names(OutputLoadings)[2:length(OutputLoadings)]) {
  TempData <- OutputLoadings %>%
    select(Factor, any_of(col)) %>%
    rename(Correlation = col) %>%
    mutate(AbsCorrelation = abs(Correlation),
           EffectDirection = ifelse(Correlation < 0, "Negative", "Positive")
           ) %>%
    arrange(desc(AbsCorrelation))
  rownames(TempData) <- 1:nrow(TempData) 
  TempData <- TempData[1:CorrToKeep, ]
  OutputLoadingsSummary <- rbind(OutputLoadingsSummary, TempData)
}

# Sorting the data by component and corr strength for improved presentability
OutputLoadingsSummary$Component <- sort(rep(ColNames, CorrToKeep))
OutputLoadingsSummary <- OutputLoadingsSummary %>%
  arrange(Component, desc(Correlation)) %>%
  select(Component, Factor, Correlation, AbsCorrelation, EffectDirection)

# Showing the data
OutputLoadingsSummary
```

<br/>

The table above tells us which individual factors are most strongly correlated with the component created by the PCA. Based on the **top 5 strongest correlates**, we can make the following conclusions about what the different factors represent:

-   **Economics_Comp.1**: represents the reverse of poverty; will be called `LackOfPoverty` from this point onward

-   **Economics_Comp.2**: represents the reverse of unemployment; will be called `LackOfUnemployment` from this point onward

-   **Economics_Comp.3**: represents economic activity measurable by GDP and trade (both imports and exports); will be called `TradeAndGDP` from this point onward

-   **Economics_Comp.4**: contains different measures of public health expenditure and total taxation; will be called `PublicHealthExpenditure` from this point onward

-   **Economics_Comp.5**: represents income tax and redistribution, including inequality as measured by the Gini coefficient; will be called `Taxation` from this point onward

For simplicity's sake, we rename these components in line with our assumptions.

```{r pca_economics_names, echo = FALSE}
# Specifying custom column names
CustomColNames <- c("LackOfPoverty",
                    "LackOfUnemployment",
                    "TradeAndGDP",
                    "PublicHealthExpenditure",
                    "Taxation")

# Creating a new df, renaming cols and doing a bit of clean-up
EconomicData_Comp <- OutputData
names(EconomicData_Comp) <- c("RowID", CustomColNames)
rm(OutputData, OutputLoadings, OutputLoadingsSummary, PCA_EconomicData)
```

<br/>

# Political dimensions

Below, generate a series of dimensions that build upon all politics-related variables in our dataset (*N*=12). The chart below shows how much of the variance captured in the data is represented in each of the dimensions generated by the PCA:

```{r pca_politics_fit, echo = FALSE}
# Keeping data related to politics only
PoliticalData <- DataForAnalysis %>%
  select(RowID, starts_with("P_")) %>%
  drop_na()

# Creating a temp df without RowID and standardizing
# all variables around their mean
PoliticalData_ForPA <- PoliticalData %>%
  select(-RowID) %>%
  mutate(across(everything(), ~ scale(.)))

# Temporarily replacing weirdly spelled column names
# and automatically specifying model to use for the CFA
PoliticalData_ForPA <- create_temp_names(PoliticalData_ForPA)
ColsToUse <- names(PoliticalData_ForPA)

# Fitting the model
PCA_PoliticalData <- princomp(x = PoliticalData_ForPA)

# Visualizing the model's output
fviz_eig(PCA_PoliticalData, addlabels = TRUE)
```

<br/>

Examining the output, we see that by sticking to the **first 2 dimensions**, we will already be accounting for **83% of the variance** in the data. Keeping those dimension only, our political data would look like this:

```{r pca_politics_dimensions, echo = FALSE}
# Defining how many dimensions to keep in the PCA output
DimensionToKeep <- 2

# Storing the results of the PCA and re-adding RowID
OutputData <- as.data.frame(PCA_PoliticalData$scores) %>%
  setNames(paste0("Politics_", names(.)))
ListOfIDs <- PoliticalData$RowID
OutputData <- OutputData[, 1:DimensionToKeep] %>%
  mutate(RowID = ListOfIDs) %>%
  select(RowID, everything())

# Previewing the data
head(OutputData, 5)
```

<br/>

This way, we have reduced the total number of dimensions by 83% while only losing 17% of the variation in the data. Below, we take a brief look at the 3 highest **absolute** **factor loadings** for the newly generated components:

```{r pca_politics_correlates, echo = FALSE}
# Defining how many of the correlates to keep for getting a better understanding of what the components represent
CorrToKeep <- 3

# Extracting the factor loadings
OutputLoadings <- data.frame(PCA_PoliticalData$loadings[, 1:DimensionToKeep])

# Adding the actual column names
OutputLoadings <- OutputLoadings %>%
  mutate(Factor = OriginalColNames) %>%
  select(Factor, everything())

# Ensuring the factors have the same names
ColNames <- names(OutputData)[2:length(names(OutputData))]
names(OutputLoadings) <- c("Factor", ColNames)

# Identifying the top N strongest correlates for each component
OutputLoadingsSummary <- data.frame()
for (col in names(OutputLoadings)[2:length(OutputLoadings)]) {
  TempData <- OutputLoadings %>%
    select(Factor, any_of(col)) %>%
    rename(Correlation = col) %>%
    mutate(AbsCorrelation = abs(Correlation),
           EffectDirection = ifelse(Correlation < 0, "Negative", "Positive")
           ) %>%
    arrange(desc(AbsCorrelation))
  rownames(TempData) <- 1:nrow(TempData) 
  TempData <- TempData[1:CorrToKeep, ]
  OutputLoadingsSummary <- rbind(OutputLoadingsSummary, TempData)
}

# Sorting the data by component and corr strength for improved presentability
OutputLoadingsSummary$Component <- sort(rep(ColNames, CorrToKeep))
OutputLoadingsSummary <- OutputLoadingsSummary %>%
  arrange(Component, desc(Correlation)) %>%
  select(Component, Factor, Correlation, AbsCorrelation, EffectDirection)

# Showing the data
OutputLoadingsSummary
```

<br/>

Based on the **top 3 strongest correlates**, we can make the following conclusions about what the different factors represent:

-   **Politics_Comp.1**: represents elections and accountability; will be called `ElectionsAndAccountability` from this point onward

-   **Politics_Comp.2**: represents the reverse of the "quality" of the elected officials and the extent to which the population can actively participate in politics; will be called `LackOfPoliticalFreedom` from this point onward

For simplicity's sake, we rename these components in line with our assumptions.

```{r pca_politics_names, echo = FALSE}
# Specifying custom column names
CustomColNames <- c("ElectionsAndAccountability",
                    "LackOfPoliticalFreedom")

# Creating a new df, renaming cols and doing a bit of clean-up
PoliticalData_Comp <- OutputData
names(PoliticalData_Comp) <- c("RowID", CustomColNames)
rm(OutputData, OutputLoadings, OutputLoadingsSummary, PCA_PoliticalData)
```

<br/>

# Social dimensions

Below, generate a series of dimensions that build upon all society-related variables in our dataset (*N*=21). The chart below shows how much of the variance captured in the data is represented in each of the dimensions generated by the PCA:

```{r pca_social_fit, echo = FALSE}
# Keeping data related to politics only
SocialData <- DataForAnalysis %>%
  select(RowID, starts_with("S_")) %>%
  drop_na()

# To avoid issues with negative covariances,
# we need to manually remove variables that are
# perfectly correlated with other variables
SocialData <- SocialData %>%
  select(-S_TotalPopulation)

# Creating a temp df without RowID and standardizing
# all variables around their mean
SocialData_ForPA <- SocialData %>%
  select(-RowID) %>%
  mutate(across(everything(), ~ scale(.)))

# Temporarily replacing weirdly spelled column names
# and automatically specifying model to use for the CFA
SocialData_ForPA <- create_temp_names(SocialData_ForPA)
ColsToUse <- names(SocialData_ForPA)

# Fitting the model
PCA_SocialData <- princomp(x = SocialData_ForPA)

# Visualizing the model's output
fviz_eig(PCA_SocialData, addlabels = TRUE)
```

<br/>

Examining the output, we see that by sticking to the **first 4 dimensions**, we will already be accounting for **81% of the variance** in the data. Keeping those dimension only, our societal data would look like this:

```{r pca_social_dimensions, echo = FALSE}
# Defining how many dimensions to keep in the PCA output
DimensionToKeep <- 4

# Storing the results of the PCA and re-adding RowID
OutputData <- as.data.frame(PCA_SocialData$scores) %>%
  setNames(paste0("Society_", names(.)))
ListOfIDs <- SocialData$RowID
OutputData <- OutputData[, 1:DimensionToKeep] %>%
  mutate(RowID = ListOfIDs) %>%
  select(RowID, everything())

# Previewing the data
head(OutputData, 5)
```

<br/>

This way, we have reduced the total number of dimensions by 81% while only losing 19% of the variation in the data. Below, we take a brief look at the 4 highest **absolute** **factor loadings** for the newly generated components:

```{r pca_social_correlates, echo = FALSE}
# Defining how many of the correlates to keep for getting a better understanding of what the components represent
CorrToKeep <- 3

# Extracting the factor loadings
OutputLoadings <- data.frame(PCA_SocialData$loadings[, 1:DimensionToKeep])

# Adding the actual column names
OutputLoadings <- OutputLoadings %>%
  mutate(Factor = OriginalColNames) %>%
  select(Factor, everything())

# Ensuring the factors have the same names
ColNames <- names(OutputData)[2:length(names(OutputData))]
names(OutputLoadings) <- c("Factor", ColNames)

# Identifying the top N strongest correlates for each component
OutputLoadingsSummary <- data.frame()
for (col in names(OutputLoadings)[2:length(OutputLoadings)]) {
  TempData <- OutputLoadings %>%
    select(Factor, any_of(col)) %>%
    rename(Correlation = col) %>%
    mutate(AbsCorrelation = abs(Correlation),
           EffectDirection = ifelse(Correlation < 0, "Negative", "Positive")
           ) %>%
    arrange(desc(AbsCorrelation))
  rownames(TempData) <- 1:nrow(TempData) 
  TempData <- TempData[1:CorrToKeep, ]
  OutputLoadingsSummary <- rbind(OutputLoadingsSummary, TempData)
}

# Sorting the data by component and corr strength for improved presentability
OutputLoadingsSummary$Component <- sort(rep(ColNames, CorrToKeep))
OutputLoadingsSummary <- OutputLoadingsSummary %>%
  arrange(Component, desc(Correlation)) %>%
  select(Component, Factor, Correlation, AbsCorrelation, EffectDirection)

# Showing the data
OutputLoadingsSummary
```

<br/>

Based on the **top 3 strongest correlates**, we can make the following conclusions about what the different factors represent:

-   **Society_Comp.1**: represents the lack of access to electricity and clean fuels; will be called `LackOfAccessToEnergy` from this point onward

-   **Society_Comp.2**: represents population size both in general terms and urban population; will be called `PopulationSize` from this point onward

-   **Society_Comp.3**: includes different metrics of women's participation in the labor force; will be called `WomenInLaborForce` from this point onward

-   **Society_Comp.4**: represents the number of years spent in primary and secondary education as well as the % of urban population, though the correlations are stronger to the educational attainment variables; will be called `SecondaryEducation` from this point onward

For simplicity's sake, we rename these components in line with our assumptions.

```{r pca_social_names, echo = FALSE}
# Specifying custom column names
CustomColNames <- c("LackOfAccessToEnergy",
                    "PopulationSize",
                    "WomenInLaborForce",
                    "SecondaryEducation")

# Creating a new df, renaming cols and doing a bit of clean-up
SocialData_Comp <- OutputData
names(SocialData_Comp) <- c("RowID", CustomColNames)
rm(OutputData, OutputLoadings, OutputLoadingsSummary, PCA_SocialData)
```

<br/>

# Environmental dimensions

Below, generate a series of dimensions that build upon all environment-related variables in our dataset (*N*=10). The chart below shows how much of the variance captured in the data is represented in each of the dimensions generated by the PCA:

```{r pca_environ_fit, echo = FALSE}
# Keeping data related to politics only
EnvironData <- DataForAnalysis %>%
  select(RowID, starts_with("V_")) %>%
  drop_na()

# Creating a temp df without RowID and standardizing
# all variables around their mean
EnvironData_ForPA <- EnvironData %>%
  select(-RowID) %>%
  mutate(across(everything(), ~ scale(.)))

# Temporarily replacing weirdly spelled column names
# and automatically specifying model to use for the CFA
EnvironData_ForPA <- create_temp_names(EnvironData_ForPA)
ColsToUse <- names(EnvironData_ForPA)

# Fitting the model
PCA_EnvironData <- princomp(x = EnvironData_ForPA)

# Visualizing the model's output
fviz_eig(PCA_EnvironData, addlabels = TRUE)
```

<br/>

Examining the output, we see that by sticking to the **first 6 dimensions**, we will already be accounting for **92% of the variance** in the data. Keeping those dimension only, our environmental data would look like this:

```{r pca_environ_dimensions, echo = FALSE}
# Defining how many dimensions to keep in the PCA output
DimensionToKeep <- 6

# Storing the results of the PCA and re-adding RowID
OutputData <- as.data.frame(PCA_EnvironData$scores) %>%
  setNames(paste0("Environment_", names(.)))
ListOfIDs <- EnvironData$RowID
OutputData <- OutputData[, 1:DimensionToKeep] %>%
  mutate(RowID = ListOfIDs) %>%
  select(RowID, everything())

# Previewing the data
head(OutputData, 5)
```

<br/>

This way, we have reduced the total number of dimensions by 33% while only losing 8% of the variation in the data. Below, we take a brief look at the 2 highest **absolute** **factor loadings** for the newly generated components:

```{r pca_environ_correlates, echo = FALSE}
# Defining how many of the correlates to keep for getting a better understanding of what the components represent
CorrToKeep <- 2

# Extracting the factor loadings
OutputLoadings <- data.frame(PCA_EnvironData$loadings[, 1:DimensionToKeep])

# Adding the actual column names
OutputLoadings <- OutputLoadings %>%
  mutate(Factor = OriginalColNames) %>%
  select(Factor, everything())

# Ensuring the factors have the same names
ColNames <- names(OutputData)[2:length(names(OutputData))]
names(OutputLoadings) <- c("Factor", ColNames)

# Identifying the top N strongest correlates for each component
OutputLoadingsSummary <- data.frame()
for (col in names(OutputLoadings)[2:length(OutputLoadings)]) {
  TempData <- OutputLoadings %>%
    select(Factor, any_of(col)) %>%
    rename(Correlation = col) %>%
    mutate(AbsCorrelation = abs(Correlation),
           EffectDirection = ifelse(Correlation < 0, "Negative", "Positive")
           ) %>%
    arrange(desc(AbsCorrelation))
  rownames(TempData) <- 1:nrow(TempData) 
  TempData <- TempData[1:CorrToKeep, ]
  OutputLoadingsSummary <- rbind(OutputLoadingsSummary, TempData)
}

# Sorting the data by component and corr strength for improved presentability
OutputLoadingsSummary$Component <- sort(rep(ColNames, CorrToKeep))
OutputLoadingsSummary <- OutputLoadingsSummary %>%
  arrange(Component, desc(Correlation)) %>%
  select(Component, Factor, Correlation, AbsCorrelation, EffectDirection)

# Showing the data
OutputLoadingsSummary
```

<br/>

Based on the **top 2 strongest correlates**, we can make the following conclusions about what the different factors represent:

-   **Environment_Comp.1**: represents different metrics related to CO2 emissions; will be called `CO2Emissions` from this point onward

-   **Environment_Comp.2**: represents the % of land area either suitable for or devoted to agriculture; will be called `AgriculturalLand` from this point onward

-   **Environment_Comp.3**: represents the combined land area of a country and its total emissions, with both factors being highly negatively correlated with the component; will be called `SmallCountry` from this point onward

-   **Environment_Comp.4**: is most strongly (negatively) correlated with the use of fertilizers per hectar; will be called `LowerFertilizerUse` from this point onward

-   **Environment_Comp.5**: represents the % of land area covered by forests and the % used for agriculture; will be called `LandUseBalance` from this point onward

-   **Environment_Comp.6**: is most strongly correlated with the CO2 emissions per capita; will be called `CO2PerCapita` from this point onward

For simplicity's sake, we rename these components in line with our assumptions.

```{r pca_environ_names, echo = FALSE}
# Specifying custom column names
CustomColNames <- c("CO2Emissions",
                    "AgriculturalLand",
                    "SmallCountry",
                    "LowerFertilizerUse",
                    "LandUseBalance",
                    "CO2PerCapita")

# Creating a new df, renaming cols and doing a bit of clean-up
EnvironData_Comp <- OutputData
names(EnvironData_Comp) <- c("RowID", CustomColNames)
rm(OutputData, OutputLoadings, OutputLoadingsSummary, PCA_EnvironData)
```

<br/>

# Health-related dimensions

Below, generate a series of dimensions that build upon all health-related variables in our dataset (*N*=5). The chart below shows how much of the variance captured in the data is represented in each of the dimensions generated by the PCA:

```{r pca_health_fit, echo = FALSE}
# Keeping data related to politics only
HealthData <- DataForAnalysis %>%
  select(RowID, starts_with("H_")) %>%
  drop_na()

# Creating a temp df without RowID and standardizing
# all variables around their mean
HealthData_ForPA <- HealthData %>%
  select(-RowID) %>%
  mutate(across(everything(), ~ scale(.)))

# Temporarily replacing weirdly spelled column names
# and automatically specifying model to use for the CFA
HealthData_ForPA <- create_temp_names(HealthData_ForPA)
ColsToUse <- names(HealthData_ForPA)

# Fitting the model
PCA_HealthData <- princomp(x = HealthData_ForPA)

# Visualizing the model's output
fviz_eig(PCA_HealthData, addlabels = TRUE)
```

<br/>

Examining the output, we see that by sticking to the **first 2 dimensions**, we will already be accounting for **84% of the variance** in the data. Keeping those dimension only, our health-related data would look like this:

```{r pca_health_dimensions, echo = FALSE}
# Defining how many dimensions to keep in the PCA output
DimensionToKeep <- 2

# Storing the results of the PCA and re-adding RowID
OutputData <- as.data.frame(PCA_HealthData$scores) %>%
  setNames(paste0("Health_", names(.)))
ListOfIDs <- HealthData$RowID
OutputData <- OutputData[, 1:DimensionToKeep] %>%
  mutate(RowID = ListOfIDs) %>%
  select(RowID, everything())

# Previewing the data
head(OutputData, 5)
```

<br/>

This way, we have reduced the total number of dimensions by 60% while only losing 16% of the variation in the data. Below, we take a brief look at the highest **absolute** **factor loading** for the newly generated components:

```{r pca_health_correlates, echo = FALSE}
# Defining how many of the correlates to keep for getting a better understanding of what the components represent
CorrToKeep <- 1

# Extracting the factor loadings
OutputLoadings <- data.frame(PCA_HealthData$loadings[, 1:DimensionToKeep])

# Adding the actual column names
OutputLoadings <- OutputLoadings %>%
  mutate(Factor = OriginalColNames) %>%
  select(Factor, everything())

# Ensuring the factors have the same names
ColNames <- names(OutputData)[2:length(names(OutputData))]
names(OutputLoadings) <- c("Factor", ColNames)

# Identifying the top N strongest correlates for each component
OutputLoadingsSummary <- data.frame()
for (col in names(OutputLoadings)[2:length(OutputLoadings)]) {
  TempData <- OutputLoadings %>%
    select(Factor, any_of(col)) %>%
    rename(Correlation = col) %>%
    mutate(AbsCorrelation = abs(Correlation),
           EffectDirection = ifelse(Correlation < 0, "Negative", "Positive")
           ) %>%
    arrange(desc(AbsCorrelation))
  rownames(TempData) <- 1:nrow(TempData) 
  TempData <- TempData[1:CorrToKeep, ]
  OutputLoadingsSummary <- rbind(OutputLoadingsSummary, TempData)
}

# Sorting the data by component and corr strength for improved presentability
OutputLoadingsSummary$Component <- sort(rep(ColNames, CorrToKeep))
OutputLoadingsSummary <- OutputLoadingsSummary %>%
  arrange(Component, desc(Correlation)) %>%
  select(Component, Factor, Correlation, AbsCorrelation, EffectDirection)

# Showing the data
OutputLoadingsSummary
```

<br/>

Based on the **strongest correlate**, we can make the following conclusions about what the different factors represent:

-   **Health_Comp.1**: represents mortality rate resulting from committing suicide; will be called `SuicideRate` from this point onward

-   **Health_Comp.2**: represents the % of the population exposed to air pollution where the volume of PM2.5 exceed the WHO's acceptable guidelines; will be called `ExposureToAirPollution` from this point onward

For simplicity's sake, we rename these components in line with our assumptions.

```{r pca_health_names, echo = FALSE}
# Specifying custom column names
CustomColNames <- c("SuicideRate",
                    "ExposureToAirPollution")

# Creating a new df, renaming cols and doing a bit of clean-up
HealthData_Comp <- OutputData
names(HealthData_Comp) <- c("RowID", CustomColNames)
rm(OutputData, OutputLoadings, OutputLoadingsSummary, PCA_HealthData)
```

<br/>

# Exporting the data

Now that we have generated reduced dimensions data for all topics, we export these so they can be used in other analyses. Please note that as we introduced some duplicate rows during our imputation procedure, we will have duplicate rows in the PCA data as well but they will all have the same values. That's why, when it comes to the PCA data, we only keep unique rows.

```{r exporting_data, echo = FALSE}
# Keeping only distinct entries
EconomicData_Comp <- EconomicData_Comp %>% distinct(RowID, .keep_all = TRUE)
PoliticalData_Comp <- PoliticalData_Comp %>% distinct(RowID, .keep_all = TRUE)
SocialData_Comp <- SocialData_Comp %>% distinct(RowID, .keep_all = TRUE)
EnvironData_Comp <- EnvironData_Comp %>% distinct(RowID, .keep_all = TRUE)
HealthData_Comp <- HealthData_Comp %>% distinct(RowID, .keep_all = TRUE)

# Exporting individual datasets
write_parquet(EconomicData_Comp, paste(AnalysisFolder, "Data/Output/EconomicData_Comp.parquet", sep = ""))
write_parquet(PoliticalData_Comp, paste(AnalysisFolder, "Data/Output/PoliticalData_Comp.parquet", sep = ""))
write_parquet(SocialData_Comp, paste(AnalysisFolder, "Data/Output/SocialData_Comp.parquet", sep = ""))
write_parquet(EnvironData_Comp, paste(AnalysisFolder, "Data/Output/EnvironData_Comp.parquet", sep = ""))
write_parquet(HealthData_Comp, paste(AnalysisFolder, "Data/Output/HealthData_Comp.parquet", sep = ""))

# Printing a confirmation to the user
print("The data containing a reduced number of dimensions have been exported to the local folder.")
```
